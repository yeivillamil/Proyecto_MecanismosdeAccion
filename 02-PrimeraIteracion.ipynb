{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICACIÓN - Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOMBRES**:\n",
    "* Andrea Marcela Castrillon Buitrago\n",
    "* Yeison Fernando Villamil Franco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como fue indicado en el notebook de entrenamiento, debido a que no se tiene un conocimiento profundo del comportamiento de las respuestas de las expresiones génicas y viabilidad celular, se deciden tomar todos los valores. El problema de clasificación, muestra un dataset desbalanceado.\n",
    "\n",
    "Como primera iteración, serán seleccionados dos proteínas (variables de salida) con pocas activaciones o valores de 1 y con la proteína que tiene la mayor cantidad de activicaciones para evaluar los modelos: \n",
    "\n",
    "* Naive Bayes - Multinomial\n",
    "* Regresión logística\n",
    "* Random Forest\n",
    "* Máquinas de soporte vectorial (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_target = pd.read_csv('train_targets_scored.csv')\n",
    "test_features = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape, train_target.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar un filtro para hacer un entrenamiento que tenga una perturbación con químicos. Para el caso de los datos, estos son con `trt_cp`. Considerando los mismo tiempos de dosis, y la dosis.\n",
    "\n",
    "Se realizará primero un `merger` para poder quitar la misma cantidad de filas en el Xtrain y ytrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([train_features, train_target], axis = 1)\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[data_train['cp_type'] == 'trt_cp']\n",
    "# data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prob = test_features[test_features['cp_type'] == 'trt_cp']\n",
    "# X_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train.iloc[:,4:876]\n",
    "y = data_train.iloc[:,877:]\n",
    "X_prob_test = X_prob.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y['5-alpha_reductase_inhibitor']\n",
    "y_t2 = y['nfkb_inhibitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, X_prob_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrados los dataframe, se procederá a tomar un label para hacer un prueba para modelos de clasificación sencillos. Para el caso del `y` de entrenamiento, serán tomados dos etiquetas (label). (Se realizará una prueba con un label con pocos valores de 1 y posteriormente, con más valores de 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generará un split para poder tener un datos de train y test estratificado en función de la variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_t, random_state = 42, test_size=0.3, stratify = y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y_t2, random_state = 42, test_size=0.3, stratify = y_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis para la salida `5-alpha_reductase_inhibitor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.hist()\n",
    "# y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_target[train_target.columns[137]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analísis de la salida `nfkb_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `5-alpha_reductase_inhibitor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Para la estandarización (normalización) de los datos, el modelo de Bayes no permite usar valores negativos. Se decide usar `MinMaxScaler` para no tener valores negativos en la variables de entrada.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_entren = np.array(y_train)\n",
    "y_prueba= np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainnp = X_train.iloc[:,:].to_numpy()\n",
    "# X_testnp = X_test.iloc[:,:].to_numpy()\n",
    "# y_trainnp = y_train.iloc[:,:].to_numpy()\n",
    "# y_testnp = y_test.iloc[:,:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_n = scaler.transform(X_train)\n",
    "X_test_n = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler1 = MinMaxScaler().fit(X_train)\n",
    "X_train_max = scaler1.transform(X_train)\n",
    "X_test_max = scaler1.transform(X_test)\n",
    "X_test_prob = scaler1.transform(X_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "cv = StratifiedShuffleSplit(n_splits = nfolds)\n",
    "# pred_prob = np.zeros((X_prob_test.shape[0], y_trainnp.shape[1]))\n",
    "# pred_train = np.zeros((X_train_max.shape[0], y_trainnp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "\n",
    "for fn, (train_ind, val_ind) in enumerate(cv.split(X_train_max, y_entren)):\n",
    "    print('Starting fold', fn)\n",
    "    X_tr, X_val = X_train_max[train_ind], X_train_max[val_ind]\n",
    "    y_tr, y_val = y_entren[train_ind], y_entren[val_ind]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf.predict(X_tr)\n",
    "    y_vali = clf.predict(X_val)\n",
    "    \n",
    "    error_pred = balanced_accuracy_score(np.ravel(y_tr), y_pred)\n",
    "    error_val = balanced_accuracy_score(np.ravel(y_val), y_vali)\n",
    "    \n",
    "print('BAC de entrenamiento =', error_pred)\n",
    "print('BAC de validación =', error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder().fit(np.unique(y['5-alpha_reductase_inhibitor']))\n",
    "\n",
    "pred_test = clf.predict(X_test_max)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf, X_test_max, y_prueba, display_labels=np.unique(y['5-alpha_reductase_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - MNB(5-alpha_reductase_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `nfkb_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_entren2 = np.array(y_train2)\n",
    "y_prueba2= np.array(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler().fit(X_train2)\n",
    "X_train_n2 = scaler2.transform(X_train2)\n",
    "X_test_n2 = scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ = MinMaxScaler().fit(X_train2)\n",
    "X_train_max2 = scaler_.transform(X_train2)\n",
    "X_test_max2 = scaler_.transform(X_test2)\n",
    "X_test_prob = scaler_.transform(X_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "\n",
    "for fn, (train_ind, val_ind) in enumerate(cv.split(X_train_max2, y_entren2)):\n",
    "    print('Starting fold', fn)\n",
    "    X_tr, X_val = X_train_max2[train_ind], X_train_max2[val_ind]\n",
    "    y_tr, y_val = y_entren2[train_ind], y_entren2[val_ind]\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf.predict(X_tr)\n",
    "    y_vali = clf.predict(X_val)\n",
    "    \n",
    "    error_pred = balanced_accuracy_score(np.ravel(y_tr), y_pred)\n",
    "    error_val = balanced_accuracy_score(np.ravel(y_val), y_vali)\n",
    "    \n",
    "print('BAC de entrenamiento =', error_pred)\n",
    "print('BAC de validación =', error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['nfkb_inhibitor']))\n",
    "\n",
    "pred_test = clf.predict(X_test_max2)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba2,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba2,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba2),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf, X_test_max2, y_prueba2, display_labels=np.unique(y['nfkb_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - MNB(nfkb_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `5-alpha_reductase_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf2 = LogisticRegression(random_state = 17, class_weight = 'balanced', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv1 = StratifiedShuffleSplit(n_splits = 6)\n",
    "\n",
    "for fn, (train_ind, val_ind) in enumerate(cv.split(X_train_n, y_entren)):\n",
    "    print('Starting fold', fn)\n",
    "    X_tr, X_val = X_train_n[train_ind], X_train_n[val_ind]\n",
    "    y_tr, y_val = y_entren[train_ind], y_entren[val_ind]\n",
    "    clf2.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf2.predict(X_tr)\n",
    "    y_vali = clf2.predict(X_val)\n",
    "    \n",
    "    error_pred = balanced_accuracy_score(y_tr, y_pred)\n",
    "    error_val = balanced_accuracy_score(y_val, y_vali)\n",
    "    \n",
    "print('BAC de entrenamiento =', error_pred)\n",
    "print('BAC de validación =', error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['5-alpha_reductase_inhibitor']))\n",
    "\n",
    "pred_test = clf2.predict(X_test_n)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf2, X_test_n, y_prueba, display_labels=np.unique(y['5-alpha_reductase_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - LR(5-alpha_reductase_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `nfkb_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn, (train_ind, val_ind) in enumerate(cv.split(X_train_n2, y_entren2)):\n",
    "    print('Starting fold', fn)\n",
    "    X_tr, X_val = X_train_n2[train_ind], X_train_n2[val_ind]\n",
    "    y_tr, y_val = y_entren2[train_ind], y_entren2[val_ind]\n",
    "    clf2.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_pred = clf2.predict(X_tr)\n",
    "    y_vali = clf2.predict(X_val)\n",
    "    \n",
    "    error_pred = balanced_accuracy_score(y_tr, y_pred)\n",
    "    error_val = balanced_accuracy_score(y_val, y_vali)\n",
    "    \n",
    "print('BAC de entrenamiento =', error_pred)\n",
    "print('BAC de validación =', error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['nfkb_inhibitor']))\n",
    "\n",
    "pred_test = clf2.predict(X_test_n2)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba2,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba2,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba2),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf2, X_test_n2, y_prueba2, display_labels=np.unique(y['nfkb_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - LR(nfkb_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `5-alpha_reductase_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_b = RandomForestClassifier(random_state=0, class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[20,40,60,80,100,120], 'max_depth':[2,4,6,8], 'max_features':[10,20,30,40,50]}\n",
    "\n",
    "clf_5 = GridSearchCV(estimator=clf_b, param_grid=parameters, cv=cv, scoring='balanced_accuracy', return_train_score=True, verbose=5)\n",
    "clf_5.fit(X_train_n, y_entren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['5-alpha_reductase_inhibitor']))\n",
    "\n",
    "pred_test = clf_5.predict(X_test_n)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf_5, X_test_n, y_prueba, display_labels=np.unique(y['5-alpha_reductase_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - LR(5-alpha_reductase_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `nfkb_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':[20,40,60,80,100,120], 'max_depth':[2,4,6,8], 'max_features':[10,20,30,40,50]}\n",
    "\n",
    "clf_4 = GridSearchCV(estimator=clf_b, param_grid=parameters, cv=cv, scoring='balanced_accuracy', return_train_score=True, verbose=5)\n",
    "clf_4.fit(X_train_n2, y_entren2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['nfkb_inhibitor']))\n",
    "\n",
    "pred_test = clf_4.predict(X_test_n2)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba2,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba2,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba2),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf_4, X_test_n2, y_prueba2, display_labels=np.unique(y['nfkb_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - RF (nfkb_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de soporte vectorial (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `5-alpha_reductase_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(4)\n",
    "\n",
    "#Número de vecinos a evaluar\n",
    "gamma=[0.01, 0.1, 1]\n",
    "param_reg = [0.01, 0.1, 1, 10]\n",
    "\n",
    "svm = SVC(class_weight = 'balanced')\n",
    "\n",
    "parameters = {'kernel':['linear','poly','rbf'], 'gamma':gamma, 'C':param_reg}\n",
    "\n",
    "clf_2 = GridSearchCV(estimator=svm, param_grid = parameters, cv=cv, scoring='balanced_accuracy',return_train_score=True, verbose=5)\n",
    "clf_2.fit(X_train_n, y_entren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_2.best_params_)\n",
    "print(clf_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['5-alpha_reductase_inhibitor']))\n",
    "\n",
    "pred_test = clf_2.predict(X_test_n)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf_2, X_test_n, y_prueba, display_labels=np.unique(y['5-alpha_reductase_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - LR(5-alpha_reductase_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label --> `nfkb_inhibitor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=[0.01, 0.1, 1]\n",
    "param_reg = [0.01, 0.1, 1, 10]\n",
    "\n",
    "svm = SVC()#class_weight = 'balanced')\n",
    "\n",
    "parameters = {'kernel':['linear','rbf'], 'gamma':gamma, 'C':param_reg}\n",
    "\n",
    "clf_3 = GridSearchCV(estimator=svm, param_grid = parameters, cv=cv, scoring='balanced_accuracy',return_train_score=True, verbose=5)\n",
    "clf_3.fit(X_train_max2, y_entren2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf_3.best_params_)\n",
    "print(clf_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(np.unique(y['nfkb_inhibitor']))\n",
    "\n",
    "pred_test = clf_3.predict(X_test_max2)\n",
    "# y_pre = pred_test.reshape(-1)\n",
    "# y_test_n = y_testnp.reshape(-1)\n",
    "\n",
    "print(f\"Accuracy = {accuracy_score(y_prueba2,pred_test)}\")\n",
    "print(f\"Balanced Accuracy = {balanced_accuracy_score(y_prueba2,pred_test)}\")\n",
    "\n",
    "#Las métricas F1, precision and recall requieren que se establezca la convención de cuál es la clase positiva (1)\n",
    "print(f\"F1 = {f1_score(le.transform(y_prueba2),le.transform(pred_test))}\")\n",
    "\n",
    "disp = plot_confusion_matrix(clf_3, X_test_max2, y_prueba2, display_labels=np.unique(y['nfkb_inhibitor']),\n",
    "                             cmap=plt.cm.Blues, \n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('MC normalizada - RF (nfkb_inhibitor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en las matrices de confusión, a pesar del desbalance que existe en las etiquetas, un valor de 874 fue suficiente para tener un resultado significativo para la variable de salida con más activaciones. Sin embargo, un valor pequeño de activaciones, no le permitieron a los modelos clasificar las activaciones de forma positiva.\n",
    "\n",
    "Los objetivos a ejecutar próximamente serán:\n",
    "* Probar modelos de clasificación que permitan darle un peso balance a las clases.\n",
    "* Estos modelos serán usados para las etiquetas con mayores activaciones.\n",
    "* Se probará el modeo SMOTE con el objetivo de crear datos sintéticos y poder darle peso a la clase con menos datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
