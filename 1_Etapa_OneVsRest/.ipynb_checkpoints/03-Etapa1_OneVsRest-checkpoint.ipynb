{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ETAPA: One Vs Rest\n",
    "\n",
    "## Entrenamiento con las proteínas con activaciones mayores a 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los objetivos en este inicio de la primera etapa es reducir el problema de 206 proteínas a solo 41 (siendo estas las de mayor activación o activaciones mayores a 100. Esto significa que más de 100 fármacos generaron que se activaran). Esto para reducir el problema y tener una solución inicial.\n",
    "\n",
    "Para las librerías que deben ser usadas, es importante que se instale el módulo `pip install scikit-multilearn`, ya que este no permite hacer una partición iterativa de los datos para entrenamiento y prueba, cuando se tiene problemas desbalanceados. Otros de los módulo a instalar es `pip install xgboost`, ya que este modelo de boosting es uno de los usados en la primera etapa de la experimentación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, plot_confusion_matrix, confusion_matrix, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import seaborn as sn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_target = pd.read_csv('train_targets_scored.csv')\n",
    "test_features = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features['cp_time'] = train_features['cp_time'].map({24:1, 48:2, 72:3})\n",
    "train_features['cp_dose'] = train_features['cp_dose'].map({'D1':0, 'D2':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([train_features, train_target], axis = 1)\n",
    "train = data_train[data_train['cp_type'] == 'trt_cp']\n",
    "evaluar = test_features[test_features['cp_type'] == 'trt_cp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de datos\n",
    "X = train.iloc[:,2:876]\n",
    "y = train.iloc[:,877:]\n",
    "x_eval = evaluar.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo de la cantidad de activaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher = [col for col in y.columns if (y[col].sum() > 100)]\n",
    "ytarget = y[higher]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher = [col for col in y.columns if (y[col].sum() > 300)]\n",
    "ytarget = y[higher]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_10 = ytarget.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 15))\n",
    "sns.barplot(x=ytarget.sum(axis=0).sort_values(ascending=False).values,\n",
    "            y=ytarget.sum(axis=0).sort_values(ascending=False).index)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "# plt.xticks(rotation=45)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Conteo proteínas con activaciones mayor a 100', size=15, pad=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteo por tipo de MoA (proteína)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Inhibidores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "inhibitor = high_10.loc[high_10.index.str.contains('_inhibitor')]\n",
    "sns.barplot(x=inhibitor.sort_values(ascending=False).values,\n",
    "            y=inhibitor.sort_values(ascending=False).index)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "# plt.xticks(rotation=30)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Mayor a 100 (Inhibidores)', size=15, pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Antagonistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "antago = high_10.loc[high_10.index.str.contains('_antagonist')]\n",
    "sns.barplot(x=antago.sort_values(ascending=False).values,\n",
    "            y=antago.sort_values(ascending=False).index)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "# plt.xticks(rotation=90)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Mayor a 100 (Antagonistas)', size=15, pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Agonista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "agonist = high_10.loc[high_10.index.str.contains('_agonist')]\n",
    "sns.barplot(x=agonist.sort_values(ascending=False).values,\n",
    "            y=agonist.sort_values(ascending=False).index)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "# plt.xticks(rotation=90)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Mayor a 100 (Agonista)', size=15, pad=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(train['sig_id'])), train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel data stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probando 4 labels\n",
    "ytarget_1 = ytarget.iloc[:,0:4]\n",
    "# ytarget_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.array(X), np.array(ytarget), test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación usando el split iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(ytarget.columns):\n",
    "    # Ptrain = (np.count_nonzero(y_train[:,i:i+1])/len(y_train[:,i:i+1]))*1.02\n",
    "    Ptrain = np.count_nonzero(y_train[:,i:i+1])*1.2/len(y_train[:,i:i+1])\n",
    "    print('Proteina =', col)\n",
    "    print(round(Ptrain, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(ytarget.columns):\n",
    "    Ptrain = (np.count_nonzero(y_train[:,i:i+1])/len(y_train[:,i:i+1]))*100\n",
    "    Ptest = (np.count_nonzero(y_test[:,i:i+1])/len(y_test[:,i:i+1]))*100\n",
    "    print('Proteina =', col)\n",
    "    print(round(Ptrain, 3), round(Ptest,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(ytarget.columns):\n",
    "    Ptrain = (np.count_nonzero(y_train[:,i:i+1]))\n",
    "    Ptest = (np.count_nonzero(y_test[:,i:i+1]))\n",
    "    print('Proteina =', col)\n",
    "    print(round(Ptrain, 3), round(Ptest,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "cv = StratifiedShuffleSplit(n_splits = nfolds)\n",
    "# cv = StratifiedKFold(n_splits = nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos iterative_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la partición iterativa, son separados los diferentes conjuntos para entrenamiento y prueba. A continuación se encuentran las funciones usadas para la ejecución de cada uno de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loga_loss(y_test, y_pred, eps=1e-15):\n",
    "    \"\"\"función para el cálculo de la perdida logarítmica establecida en el concurso de kaggle\n",
    "    \n",
    "    y_test --> Variable de salida de prueba\n",
    "    \n",
    "    y_pred --> Variable predicha (Predicción de probabilidad de activación)\"\"\"\n",
    "    \n",
    "    los = np.zeros(y_test.shape)\n",
    "    n, m = y_test.shape\n",
    "    y_true = np.clip(y_test, eps, 1-eps)\n",
    "    for M in range(m):\n",
    "        for N in range(n):\n",
    "            log_los = -((y_true[N,M]*np.log(y_pred[N,M]+eps))+((1-y_true[N,M])*np.log(1-y_pred[N,M]+eps)))\n",
    "            los[N,M] = log_los\n",
    "    return los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(loga_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_mol(x_train, y_train, parameters, modelo, ML_model=None):\n",
    "    ''' Función para la evaluación de modelos mediante la aplicación de GridSerachCV que permite la combinación de hiperparámetros y cross-validation:\n",
    "\n",
    "    x_train --> df de entrenamiento para todas las proteínas creados de manera iterativa y estratificada\n",
    "\n",
    "    y_train --> Variable de salida de entrenamiento para cada proteína\n",
    "\n",
    "    parameters --> Hiperparámetros de cada modelo de clasificación\n",
    "\n",
    "    ML_model --> Modelos de clasificación\n",
    "\n",
    "    modelo --> Lista que debe ser retornada, almacenando los modelos para cada proteína y que será usada para la construcción de las matrices de confusión'''\n",
    "\n",
    "    for i, col in enumerate(ytarget.columns):\n",
    "        #Escalado\n",
    "        scaler = MinMaxScaler()\n",
    "#         scaler = RobustScaler()\n",
    "        pipe = Pipeline(steps=[('scaler', scaler), ('ML_model', ML_model)])\n",
    "\n",
    "        ##Entrenamiento del modelo con combinaciones de hiperparámetros\n",
    "        print(\"PROTEINA =\", col)\n",
    "        gridt = GridSearchCV(estimator=pipe, param_grid=parameters, cv=cv, return_train_score=True, verbose=5, n_jobs=-1, scoring='neg_log_loss')\n",
    "        gridt.fit(x_train, np.ravel(y_train[:,i:i+1]))\n",
    "\n",
    "        ## Mejor puntuación (score) para las diferentes cross-validation realizadas\n",
    "        score = gridt.best_score_ \n",
    "        print(\"Score = \", round(score, 3))\n",
    "\n",
    "        ## Almacenamiento de los modelos para cada proteína\n",
    "        modelo.append(gridt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_conf(modelo, x_test, y_test, prediction, c_mat):\n",
    "    ''' Función para la construcción de las funciones de las matrices de confusión para cada uno de las etiquetas (proteínas) que están siendo evaluadas:\n",
    "\n",
    "    modelo -> Una lista donde se encuentran guardados los modelos entrenados de cada proteína del paso anterior\n",
    "\n",
    "    x_test -> df creada para pruebas (de forma iterativa para que funcione para todas las proteínas de forma estratificada)\n",
    "\n",
    "    y_test -> variable de salida por proteína de forma debidamente estritifica\n",
    "\n",
    "    prediction -> Lista que debe retornarse con cada una de las predicciones \n",
    "    \n",
    "    c_mat -> Retorna las matrices de confusión para cada proteínas para evaluar una métrica global'''\n",
    "\n",
    "    for i, col in enumerate(ytarget.columns):\n",
    "\n",
    "        ##Predicciones\n",
    "        pred_test = modelo[i].predict(x_test)\n",
    "        pred_proba = modelo[i].predict_proba(x_test)\n",
    "        ## Métricas usadas para medir la eficiencia del modelo (para cada proteína)\n",
    "        accuracy = accuracy_score(y_test[:,i:i+1],pred_test)\n",
    "        bal_accuracy = balanced_accuracy_score(y_test[:,i:i+1],pred_test)\n",
    "        recall = recall_score(y_test[:,i:i+1],pred_test)\n",
    "        precision = precision_score(y_test[:,i:i+1],pred_test)\n",
    "        log_loss = loga_loss(y_test[:,i:i+1], pred_proba[:,1].reshape(-1,1))\n",
    "        print(\"PROTEINA =\", col)\n",
    "        print(\"Accuracy =\", round(accuracy, 3))\n",
    "        print(\"Balanced Accuracy =\", round(bal_accuracy, 3))\n",
    "        print(\"Recall score =\", round(recall, 3))\n",
    "        print(\"Precision score =\", round(precision, 3))\n",
    "        f1 = f1_score(y_test[:,i:i+1], pred_test)\n",
    "        print(\"F1 =\", round(f1,3))\n",
    "        print(\"Log_loss =\", round(np.mean(log_loss),3))\n",
    "\n",
    "        ##Matriz de confusión\n",
    "        con_max = confusion_matrix(y_test[:,i:i+1], pred_test)\n",
    "        disp = plot_confusion_matrix(modelo[i], x_test, y_test[:,i:i+1], display_labels=np.unique(np.unique(y_test[:,i:i+1])), cmap=plt.cm.Blues, normalize=None) #normalize='true')\n",
    "        disp.ax_.set_title(col)\n",
    "        plt.show()\n",
    "\n",
    "        ## Listas creadas para almacenar las predicciones y matrices de confusión\n",
    "        prediction.append(pred_test)\n",
    "        c_mat.append(con_max)\n",
    "        print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_metric(ytest, prediction, con_mat, metric=None):\n",
    "    '''Función para la medición de una métrica global sopesada para cada uno de los modelo evaluados sobre las proteínas:\n",
    "\n",
    "    ytest --> Variable de salida para cada una de las proteínas\n",
    "\n",
    "    predictions --> predicciones calculadas para cada de las proteínas\n",
    "\n",
    "    con_mat --> Matrices de confusión de donde serán extraídos los valores obtenidos para cada uno de los modelos de clasificación'''\n",
    "    lista = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "    \n",
    "        ##Cálculo de las métricas\n",
    "        g_m = metric(y_test[:,i:i+1],np.array(prediction[i]))\n",
    "\n",
    "        ##Valor predichos correctamente\n",
    "        w_cla = con_mat[i][1,1]\n",
    "        b_cla = con_mat[i][1,0]\n",
    "\n",
    "        ##Métrica global\n",
    "        g_met = (w_cla/(b_cla+w_cla)) * g_m\n",
    "        lista.append(g_met)\n",
    "\n",
    "    g_metric = round((np.sum(lista)/len(lista)),3)\n",
    "    print(f'El valor global de {metric.__name__} es {g_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_logloss(xtest, ytest, conmat, modelo):\n",
    "    \"\"\"Función para calcular la perdida logarítmica (cross-entropy) para cada uno de los modelos. Es importante que esta perdida se mide en función de la probabilidad de que una proteína se active a la aplicación de un fármaco:\n",
    "\n",
    "    xtest --> dataset de prueba con cada una de las variables (génicas y celulares)\n",
    "\n",
    "    y_test --> dataset de prueba para cada una de las proteínas\n",
    "\n",
    "    conmat --> Lista con las matrices de confusión para cada una de las proteínas (es usada para tener una métrica sopesada en función de las activaciones)\n",
    "    \n",
    "    modelo --> Lista con los modelos para cada una de las proteínas\"\"\"\n",
    "    \n",
    "    lista = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "\n",
    "        pred_proba = modelo[i].predict_proba(xtest)\n",
    "        ##Cálculo de las métricas\n",
    "        g_m = loga_loss(ytest[:,i:i+1], pred_proba[:,1].reshape(-1,1))\n",
    "#         g_m = log_loss(ytest[:,i:i+1], np.ravel(pred_proba[:,1]))\n",
    "\n",
    "        ##Valor predichos correctamente\n",
    "        # w_cla = conmat[i][1,1]\n",
    "        # b_cla = conmat[i][1,0]\n",
    "\n",
    "        ##Métrica global\n",
    "        # g_met = (w_cla/(b_cla+w_cla)) * np.mean(g_m)\n",
    "#         g_met = (w_cla/(b_cla+w_cla)) * g_m\n",
    "        lista.append(np.mean(g_m))\n",
    "\n",
    "    g_metric = round((np.sum(lista)/len(lista)),4)\n",
    "    # print(f'El valor global la perdida logarítmica para el {modelo.__name__} es {g_metric}')\n",
    "    print(f'Global log loss --> {g_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_multiLabel_confusion_matrix(y_test_g,y_est_g):\n",
    "    n_samples, n_class = y_test_g.shape\n",
    "    CM = np.zeros((n_class,n_class))\n",
    "    Temp = np.zeros((1,n_class))\n",
    "    def acum_CM(y_test,y_est,CM,Temp):\n",
    "        ind_real = np.asarray(y_test > 0).nonzero()[0]\n",
    "        ind_est = np.asarray(y_est > 0).nonzero()[0]\n",
    "        #--------------------------------\n",
    "        if ind_real.size == 0:\n",
    "            #In case in the ground truth not even one class is active\n",
    "            Temp = Temp + y_est\n",
    "        elif ind_est.size == 0:\n",
    "            return CM, Temp\n",
    "        else:\n",
    "            mesh_real = np.array(np.meshgrid(ind_real,ind_real))\n",
    "            comb_real = mesh_real.T.reshape(-1, 2)\n",
    "            ind_remove_real = comb_real[:,0] != comb_real[:,1]\n",
    "            comb_real = comb_real[ind_remove_real]\n",
    "            #--------------------------------\n",
    "            mesh_est = np.array(np.meshgrid(ind_real,ind_est))\n",
    "            comb_est = mesh_est.T.reshape(-1, 2)\n",
    "            #--------------------------------\n",
    "            comb_real2 = comb_real[:,0] + comb_real[:,1]*1j\n",
    "            comb_est2 = comb_est[:,0] + comb_est[:,1]*1j\n",
    "            ind_remove = np.in1d(comb_est2,comb_real2)\n",
    "            comb_est = comb_est[np.logical_not(ind_remove)]\n",
    "            #--------------------------------\n",
    "            CM[comb_est[:,0],comb_est[:,1]] += 1\n",
    "        return CM, Temp\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        CM,Temp = acum_CM(y_test_g[i,:],y_est_g[i,:],CM,Temp)\n",
    "        \n",
    "    return CM,Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight = 'balanced', max_iter=1000)\n",
    "model_log = []\n",
    "parameters = {'ML_model__penalty':['l2'], 'ML_model__C': [0.1, 0.5, 1]}\n",
    "ML_mol(X_train, y_train, parameters, model_log, ML_model=clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lg, con_mat_lg = [], []\n",
    "matrix_conf(model_log, X_test, y_test, prediction_lg, con_mat_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Métricas globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las métricas globales para el modelo de regresion logística son:')\n",
    "global_metric(y_test, prediction_lg, con_mat_lg, metric=f1_score)\n",
    "global_metric(y_test, prediction_lg, con_mat_lg, metric=accuracy_score)\n",
    "global_metric(y_test, prediction_lg, con_mat_lg, metric=balanced_accuracy_score)\n",
    "global_metric(y_test, prediction_lg, con_mat_lg, metric=recall_score)\n",
    "global_metric(y_test, prediction_lg, con_mat_lg, metric=precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelo de regresión logística:')\n",
    "global_logloss(X_test, y_test, con_mat_lg, model_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Matriz de confusión global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_lr, Temp = global_multiLabel_confusion_matrix(y_test, np.array(prediction_lg).T)\n",
    "\n",
    "# #Normalized\n",
    "suma = CM_lr.sum(axis=0) + Temp\n",
    "for value, col in enumerate(suma.T):\n",
    "    if col == 0:\n",
    "        suma[value] = 1\n",
    "    else:\n",
    "        suma\n",
    "CM_lr_no = CM_lr/suma\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "protein_names = np.arange(41)\n",
    "protein = ytarget.columns\n",
    "ax = sn.heatmap(CM_lr_no, annot=True, fmt='.1g', xticklabels = protein, yticklabels = protein_names)\n",
    "\n",
    "plt.title('Global multi-label confusion matrix - Logistic regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(criterion='entropy', class_weight='balanced', n_jobs=-1)\n",
    "modelo_rf = []\n",
    "parameters_rf = {'ML_model__n_estimators':[20,40,60,80,100,120],'ML_model__max_depth':[4,6,8,10,12]}\n",
    "ML_mol(X_train, y_train, parameters_rf, modelo_rf, ML_model=model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rf, con_mat_rf = [], []\n",
    "matrix_conf(modelo_rf, X_test, y_test, prediction_rf, con_mat_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Métricas globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Las métricas globales para el modelo de arboles aleatorios son:')\n",
    "global_metric(y_test, prediction_rf, con_mat_rf, metric=f1_score)\n",
    "global_metric(y_test, prediction_rf, con_mat_rf, metric=accuracy_score)\n",
    "global_metric(y_test, prediction_rf, con_mat_rf, metric=balanced_accuracy_score)\n",
    "global_metric(y_test, prediction_rf, con_mat_rf, metric=recall_score)\n",
    "global_metric(y_test, prediction_rf, con_mat_rf, metric=precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelo Random Forest (Bosques aleatorios):')\n",
    "global_logloss(X_test, y_test, con_mat_rf, modelo_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Matriz de confusión global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CM_rf, Temp = global_multiLabel_confusion_matrix(y_test, np.array(prediction_rf).T)\n",
    "\n",
    "# #Normalized\n",
    "suma = CM_rf.sum(axis=0) + Temp\n",
    "for value, col in enumerate(suma.T):\n",
    "    if col == 0:\n",
    "        suma[value] = 1\n",
    "    else:\n",
    "        suma\n",
    "CM_rf_no = CM_rf/suma\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "protein_names = np.arange(41)\n",
    "protein = ytarget.columns\n",
    "ax = sn.heatmap(CM_rf_no, annot=True, fmt='.1g', xticklabels = protein, yticklabels = protein_names)\n",
    "\n",
    "plt.title('Global multi-label confusion matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Support vector classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_c = SVC(class_weight = 'balanced', gamma = 'scale', probability=True)\n",
    "SVM_model = []\n",
    "parameters_svm = {'ML_model__kernel':['linear','rbf'], 'ML_model__C':[0.01, 0.1, 1, 10]}\n",
    "ML_mol(X_train, y_train, parameters_svm, SVM_model, ML_model=svm_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm, con_mat_svm = [], []\n",
    "matrix_conf(SVM_model, X_test, y_test, prediction_svm, con_mat_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Métricas globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las métricas globales para el modelo de máquinas de soporte son:')\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=f1_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=accuracy_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=balanced_accuracy_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=recall_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Matriz de confusión global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_svm, Temp = global_multiLabel_confusion_matrix(y_test, np.array(prediction_svm).T)\n",
    "\n",
    "# #Normalized\n",
    "suma = CM_svm.sum(axis=0) + Temp\n",
    "for value, col in enumerate(suma.T):\n",
    "    if col == 0:\n",
    "        suma[value] = 1\n",
    "    else:\n",
    "        suma\n",
    "CM_svm_no = CM_svm/suma\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "protein_names = np.arange(41)\n",
    "protein = ytarget.columns\n",
    "ax = sn.heatmap(CM_svm_no, annot=True, fmt='.1g', xticklabels = protein, yticklabels = protein_names)\n",
    "\n",
    "plt.title('Global multi-label confusion matrix - Support Vector Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder().fit(np.unique(y_train[:,0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for i in range(len(ytarget.columns)):\n",
    "    class_we = compute_class_weight('balanced', le.classes_, y_train[:,i:i+1].flatten())\n",
    "    classes.append(class_we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in classes:\n",
    "    mean_1 = np.mean(val[1])\n",
    "    mean_2 = np.mean(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_gb = {'n_estimators':[20,40,60,80,100],'base_estimator__max_depth':[4,6,8,10]}\n",
    "parameters_xgb = {'n_estimators':[40,60,80,100],'max_depth': [2,4,6,8], 'learning_rate':[1,0.5,0.1], 'reg_lambda':[0.2]}\n",
    "estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight=mean_1/mean_2, random_state=0,use_label_encoder=False, eval_metric='logloss')#, max_delta_step=3)\n",
    "xgb_model = []\n",
    "ML_mol(X_train, y_train.astype(int), parameters_xgb, estimator, xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgb, con_mat_xgb = [], []\n",
    "matrix_conf(xgb_model, X_test, y_test, prediction_xgb, con_mat_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Métricas globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las métricas globales para el modelo xgboost son:')\n",
    "global_metric(y_test, prediction_xgb, con_mat_xgb, metric=f1_score)\n",
    "global_metric(y_test, prediction_xgb, con_mat_xgb, metric=accuracy_score)\n",
    "global_metric(y_test, prediction_xgb, con_mat_xgb, metric=balanced_accuracy_score)\n",
    "global_metric(y_test, prediction_xgb, con_mat_xgb, metric=recall_score)\n",
    "global_metric(y_test, prediction_xgb, con_mat_xgb, metric=precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelo XGBoost:')\n",
    "global_logloss(X_test, y_test, con_mat_xgb, xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Matriz de confusión global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_xgb, Temp = global_multiLabel_confusion_matrix(y_test, np.array(prediction_xgb).T)\n",
    "\n",
    "# #Normalized\n",
    "suma = CM_xgb.sum(axis=0) + Temp\n",
    "for value, col in enumerate(suma.T):\n",
    "    if col == 0:\n",
    "        suma[value] = 1\n",
    "    else:\n",
    "        suma\n",
    "CM_xgb_no = CM_xgb/suma\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "protein_names = np.arange(41)\n",
    "protein = ytarget.columns\n",
    "ax = sn.heatmap(CM_xgb_no, annot=True, fmt='.1g', xticklabels = protein, yticklabels = protein_names)\n",
    "\n",
    "plt.title('Global multi-label confusion matrix - XGboost')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
