{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Modelamiento de la máquina de soporte (SVC) y el modelo XGBoost usando GPU (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección son ejecutados las simulaciones de los modelos SVC y XGBoost a partir del uso de GPU. Este recurso fue proporcionado por la plataforma Kaggle, donde son habilidatos 30 horas semanales para su uso. Adiocionalmente y es importante mencionar, fue usada una librería de máquina de soporte que permite la paralelización de este modelo y usar recursos como GPU. En la documnetación se puede encontrar más información al respecto https://docs.rapids.ai/api/cuml/stable/. Para el uso de este recurso de SVC, es necesaria la instalación del módulo `pip install cuml`.\n",
    "\n",
    "Las librerías de los módulos en esta sección son los mismos de los archivo `03` y `04`.\n",
    "\n",
    "Para la ejecución de este notebook, es importante tener una cuenta de usuario en la plataforma kaggle y en el perfil de la persona, crear un nuevo notebook donde apareceran los recursos que se desean usar. Allí puede ser habilitada la GPU.\n",
    "\n",
    "Las librerías instaladas en los notebooks `03` y `04`, deben ser instaladas también en esta sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, plot_confusion_matrix, confusion_matrix, log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import seaborn as sn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "from cuml.svm import SVC as svc\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/train-feature-p/train_features_p.csv')\n",
    "# train_target = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "train_target = pd.read_csv('../input/train-target-p/train_targets_scored_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_=train_features.copy()\n",
    "# train_features_['cp_type'] = train_features_['cp_type'].map({'trt_cp':0, 'ctl_vehicle':1})\n",
    "train_features['cp_time'] = train_features['cp_time'].map({24:1, 48:2, 72:3})\n",
    "train_features['cp_dose'] = train_features_['cp_dose'].map({'D1':0, 'D2':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([train_features, train_target], axis = 1)\n",
    "train = data_train[data_train['cp_type'] == 'trt_cp']\n",
    "# evaluar = test_features[test_features['cp_type'] == 'trt_cp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train.iloc[:,2:876]\n",
    "y = data_train.iloc[:,877:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher = [col for col in y.columns if (y[col].sum() > 100)]\n",
    "ytarget = y[higher]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = iterative_train_test_split(np.array(X), np.array(ytarget), test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_n, y_train_n = [], []\n",
    "for i, c in enumerate(ytarget.columns):\n",
    "    perc = np.count_nonzero(y_train[:,i:i+1])*1.2/(len(y_train[:,i:i+1])-np.count_nonzero(y_train[:,i:i+1]))\n",
    "    over = SMOTE(sampling_strategy=perc)\n",
    "    xtrain, ytrain = over.fit_resample(X_train, y_train[:,i:i+1])\n",
    "    x_train_n.append(xtrain)\n",
    "    y_train_n.append(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5\n",
    "cv = StratifiedShuffleSplit(n_splits = nfolds)\n",
    "# cv = StratifiedKFold(n_splits = nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loga_loss(y_test, y_pred, eps=1e-15):\n",
    "    \"\"\"función para el cálculo de la perdida logarítmica establecida en el concurso de kaggle\n",
    "    \n",
    "    y_test --> Variable de salida de prueba\n",
    "    \n",
    "    y_pred --> Variable predicha (Predicción de probabilidad de activación)\"\"\"\n",
    "    \n",
    "    los = np.zeros(y_test.shape)\n",
    "    n, m = y_test.shape\n",
    "    y_true = np.clip(y_test, eps, 1-eps)\n",
    "    for M in range(m):\n",
    "        for N in range(n):\n",
    "            log_los = -((y_true[N,M]*np.log(y_pred[N,M]+eps))+((1-y_true[N,M])*np.log(1-y_pred[N,M]+eps)))\n",
    "            los[N,M] = log_los\n",
    "    return los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_mol(x_train, y_train, parameters, modelo, ML_model=None):\n",
    "    ''' Función para la evaluación de modelos mediante la aplicación de GridSerachCV que permite la combinación de hiperparámetros y cross-validation:\n",
    "\n",
    "    x_train --> df de entrenamiento para todas las proteínas creados de manera iterativa y estratificada\n",
    "\n",
    "    y_train --> Variable de salida de entrenamiento para cada proteína\n",
    "\n",
    "    parameters --> Hiperparámetros de cada modelo de clasificación\n",
    "\n",
    "    ML_model --> Modelos de clasificación\n",
    "\n",
    "    modelo --> Lista que debe ser retornada, almacenando los modelos para cada proteína y que será usada para la construcción de las matrices de confusión'''\n",
    "\n",
    "    for i, col in enumerate(ytarget.columns):\n",
    "        \n",
    "        #Esalamiento\n",
    "        scaler = MinMaxScaler()\n",
    "        pipe = Pipeline(steps=[('scaler', scaler),('ML_model', ML_model)])\n",
    "        ##Entrenamiento del modelo con combinaciones de hiperparámetros\n",
    "        print(\"PROTEINA =\", col)\n",
    "        gridt = GridSearchCV(estimator=pipe, param_grid=parameters, cv=cv, scoring='neg_log_loss', return_train_score=True, verbose=5, n_jobs=-1)\n",
    "        gridt.fit(x_train[i], np.ravel(y_train[i]))\n",
    "\n",
    "        ## Mejor puntuación (score) para las diferentes cross-validation realizadas\n",
    "        score = gridt.best_score_ \n",
    "        print(\"Score = \", round(score, 3))\n",
    "\n",
    "        ## Almacenamiento de los modelos para cada proteína\n",
    "        modelo.append(gridt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_conf(modelo, x_test, y_test, prediction, c_mat):\n",
    "    ''' Función para la construcción de las funciones de las matrices de confusión para cada uno de las etiquetas (proteínas) que están siendo evaluadas:\n",
    "\n",
    "    modelo -> Una lista donde se encuentran guardados los modelos entrenados de cada proteína del paso anterior\n",
    "\n",
    "    x_test -> df creada para pruebas (de forma iterativa para que funcione para todas las proteínas de forma estratificada)\n",
    "\n",
    "    y_test -> variable de salida por proteína de forma debidamente estritifica\n",
    "\n",
    "    prediction -> Lista que debe retornarse con cada una de las predicciones \n",
    "    \n",
    "    c_mat -> Retorna las matrices de confusión para cada proteínas para evaluar una métrica global'''\n",
    "\n",
    "    for i, col in enumerate(ytarget.columns):\n",
    "\n",
    "        ##Predicciones\n",
    "        pred_test = modelo[i].predict(x_test)\n",
    "#         pred_proba = modelo[i].predict_proba(x_test)\n",
    "        ## Métricas usadas para medir la eficiencia del modelo (para cada proteína)\n",
    "        accuracy = accuracy_score(y_test[:,i:i+1],pred_test)\n",
    "        bal_accuracy = balanced_accuracy_score(y_test[:,i:i+1],pred_test)\n",
    "        recall = recall_score(y_test[:,i:i+1],pred_test)\n",
    "        precision = precision_score(y_test[:,i:i+1],pred_test)\n",
    "#         log_loss_ = loga_loss(y_test[:,i:i+1].reshape(-1,1), pred_proba[:,1].reshape(-1,1), eps=1e-15)\n",
    "        print(\"PROTEINA =\", col)\n",
    "        print(\"Accuracy =\", round(accuracy, 3))\n",
    "        print(\"Balanced Accuracy =\", round(bal_accuracy, 3))\n",
    "        print(\"Recall score =\", round(recall, 3))\n",
    "        print(\"Precision score =\", round(precision, 3))\n",
    "        f1 = f1_score(y_test[:,i:i+1], pred_test)\n",
    "        print(\"F1 =\", round(f1,3))\n",
    "#         print(\"Log_loss =\", round(np.mean(log_loss_),3))\n",
    "\n",
    "        ##Matriz de confusión\n",
    "        con_max = confusion_matrix(y_test[:,i:i+1], pred_test)\n",
    "        disp = plot_confusion_matrix(modelo[i], x_test, y_test[:,i:i+1], display_labels=np.unique(np.unique(y_test[:,i:i+1])), cmap=plt.cm.Blues, normalize=None) #normalize='true')\n",
    "        disp.ax_.set_title(col)\n",
    "        plt.show()\n",
    "\n",
    "        ## Listas creadas para almacenar las predicciones y matrices de confusión\n",
    "        prediction.append(pred_test)\n",
    "        c_mat.append(con_max)\n",
    "        print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_metric(ytest, prediction, con_mat, metric=None):\n",
    "    '''Función para la medición de una métrica global sopesada para cada uno de los modelo evaluados sobre las proteínas:\n",
    "\n",
    "    ytest --> Variable de salida para cada una de las proteínas\n",
    "\n",
    "    predictions --> predicciones calculadas para cada de las proteínas\n",
    "\n",
    "    con_mat --> Matrices de confusión de donde serán extraídos los valores obtenidos para cada uno de los modelos de clasificación'''\n",
    "    lista = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "    \n",
    "        ##Cálculo de las métricas\n",
    "        g_m = metric(y_test[:,i:i+1],np.array(prediction[i]))\n",
    "\n",
    "        ##Valor predichos correctamente\n",
    "        w_cla = con_mat[i][1,1]\n",
    "        b_cla = con_mat[i][1,0]\n",
    "\n",
    "        ##Métrica global\n",
    "        g_met = (w_cla/(b_cla+w_cla)) * g_m\n",
    "        lista.append(g_met)\n",
    "\n",
    "    g_metric = round((np.sum(lista)/len(lista)),3)\n",
    "    print(f'El valor global de {metric.__name__} es {g_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_logloss(xtest, ytest, modelo):\n",
    "    \"\"\"Función para calcular la perdida logarítmica (cross-entropy) para cada uno de los modelos. Es importante que esta perdida se mide en función de la probabilidad de que una proteína se active a la aplicación de un fármaco:\n",
    "\n",
    "    xtest --> dataset de prueba con cada una de las variables (génicas y celulares)\n",
    "\n",
    "    y_test --> dataset de prueba para cada una de las proteínas\n",
    "\n",
    "    conmat --> Lista con las matrices de confusión para cada una de las proteínas (es usada para tener una métrica sopesada en función de las activaciones)\n",
    "    \n",
    "    modelo --> Lista con los modelos para cada una de las proteínas\"\"\"\n",
    "    \n",
    "    lista = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "\n",
    "        pred_proba = modelo[i].predict_proba(xtest)\n",
    "        ##Cálculo de las métricas\n",
    "        g_m = loga_loss(ytest[:,i:i+1], pred_proba[:,1].reshape(-1,1))\n",
    "\n",
    "        ##Valor predichos correctamente\n",
    "#         w_cla = conmat[i][1,1]\n",
    "#         b_cla = conmat[i][1,0]\n",
    "\n",
    "        ##Métrica global\n",
    "#         g_met = (w_cla/(b_cla+w_cla)) * g_m\n",
    "        lista.append(np.mean(g_m))\n",
    "\n",
    "    g_metric = round((np.sum(lista)/len(lista)),4)\n",
    "    # print(f'El valor global la perdida logarítmica para el {modelo.__name__} es {g_metric}')\n",
    "    print(f'Global log loss --> {g_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_multiLabel_confusion_matrix(y_test_g,y_est_g):\n",
    "    n_samples, n_class = y_test_g.shape\n",
    "    CM = np.zeros((n_class,n_class))\n",
    "    Temp = np.zeros((1,n_class))\n",
    "    def acum_CM(y_test,y_est,CM,Temp):\n",
    "        ind_real = np.asarray(y_test > 0).nonzero()[0]\n",
    "        ind_est = np.asarray(y_est > 0).nonzero()[0]\n",
    "        #--------------------------------\n",
    "        if ind_real.size == 0:\n",
    "            #In case in the ground truth not even one class is active\n",
    "            Temp = Temp + y_est\n",
    "        elif ind_est.size == 0:\n",
    "            return CM, Temp\n",
    "        else:\n",
    "            mesh_real = np.array(np.meshgrid(ind_real,ind_real))\n",
    "            comb_real = mesh_real.T.reshape(-1, 2)\n",
    "            ind_remove_real = comb_real[:,0] != comb_real[:,1]\n",
    "            comb_real = comb_real[ind_remove_real]\n",
    "            #--------------------------------\n",
    "            mesh_est = np.array(np.meshgrid(ind_real,ind_est))\n",
    "            comb_est = mesh_est.T.reshape(-1, 2)\n",
    "            #--------------------------------\n",
    "            comb_real2 = comb_real[:,0] + comb_real[:,1]*1j\n",
    "            comb_est2 = comb_est[:,0] + comb_est[:,1]*1j\n",
    "            ind_remove = np.in1d(comb_est2,comb_real2)\n",
    "            comb_est = comb_est[np.logical_not(ind_remove)]\n",
    "            #--------------------------------\n",
    "            CM[comb_est[:,0],comb_est[:,1]] += 1\n",
    "        return CM, Temp\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        CM,Temp = acum_CM(y_test_g[i,:],y_est_g[i,:],CM,Temp)\n",
    "        \n",
    "    return CM,Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support vector machine (SVC)\n",
    "\n",
    "Para este primer caso, fue realizada la ejecución del modelo SVC sin activar la probabilidad, con el objetivo de revisar resultados y poder compararlos con los obtenidos en la ejecución de los archivos `03` y `04`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svc(class_weight = 'balanced', gamma = 'scale')\n",
    "model_svm = []\n",
    "parameters_svm = {'ML_model__kernel':['linear','rbf'], 'ML_model__C':[0.01, 0.1, 1, 10]}\n",
    "ML_mol(x_train_n, y_train_n, parameters_svm, model_svm, ML_model=clf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svm, con_mat_svm = [], []\n",
    "matrix_conf(model_svm, X_test, y_test, prediction_svm, con_mat_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Las métricas globales para el modelo de máquinas de soporte son:')\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=f1_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=accuracy_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=balanced_accuracy_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=recall_score)\n",
    "global_metric(y_test, prediction_svm, con_mat_svm, metric=precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_svm, Temp = global_multiLabel_confusion_matrix(y_test, np.array(prediction_svm).T)\n",
    "\n",
    "# #Normalized\n",
    "suma = CM_svm.sum(axis=0) + Temp\n",
    "for value, col in enumerate(suma.T):\n",
    "    if col == 0:\n",
    "        suma[value] = 1\n",
    "    else:\n",
    "        suma\n",
    "CM_svm_no = CM_svm/suma\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "protein_names = np.arange(41)\n",
    "protein = ytarget.columns\n",
    "ax = sn.heatmap(CM_svm_no, annot=True, fmt='.1g', xticklabels = protein, yticklabels = protein_names)\n",
    "\n",
    "plt.title('Global multi-label confusion matrix - Support Vector Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probability for SVC (GPU)\n",
    "\n",
    "Aquí, es activada la probabilidad como hiperparámetro del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svc(class_weight = 'balanced', gamma = 'scale', probability=True)\n",
    "model_svm = []\n",
    "parameters_svm = {'ML_model__kernel':['linear','rbf'], 'ML_model__C':[0.01, 0.1, 1, 10]}\n",
    "ML_mol(x_train_n, y_train_n, parameters_svm, model_svm, ML_model=clf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The global log loss for the SVC models is:')\n",
    "global_logloss(X_test, y_test, model_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = []\n",
    "for i in range(len(ytarget.columns)):\n",
    "    class_we = compute_class_weight(class_weight='balanced', classes=[0,1], y=y_train[:,i:i+1].flatten())\n",
    "    classes.append(class_we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in classes:\n",
    "    mean_1 = np.mean(val[1])\n",
    "    mean_2 = np.mean(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_gb = {'n_estimators':[20,40,60,80,100],'base_estimator__max_depth':[4,6,8,10]}\n",
    "parameters_xgb = {'ML_model__n_estimators':[20,60,100,150,200],'ML_model__max_depth': [4,7,10,13], 'ML_model__learning_rate':[1,0.1,0.04], 'ML_model__reg_lambda':[0.2]}\n",
    "estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight=mean_1/mean_2, random_state=0,use_label_encoder=False, eval_metric='logloss', max_delta_step= 2.0706, subsample= 0.8639, min_child_weight= 31.5800, tree_method = 'gpu_hist')#, max_delta_step=3)\n",
    "xgb_model = []\n",
    "ML_mol(x_train_n, y_train_n, parameters_xgb, xgb_model, ML_model=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgb, con_mat_xgb = [], []\n",
    "matrix_conf(xgb_model, X_test, y_test, prediction_xgb, con_mat_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The global log loss for the XGBoost model is:')\n",
    "global_logloss(X_test, y_test, xgb_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
